"""
Script Principal - Aula 4: Execu√ß√£o na Nuvem
Integra compute clusters, data assets, execu√ß√£o e automa√ß√£o
"""
import os
from azure.ai.ml import MLClient
from azure.identity import DefaultAzureCredential

def main_cloud_execution_workflow():
    """Workflow principal de execu√ß√£o na nuvem"""

    print("EXECU√á√ÉO NA NUVEM - AZURE ML")
    print("=" * 80)

    try:
        # 1. Conectar ao Azure ML Workspace
        print("\nCONECTANDO AO WORKSPACE")
        print("-" * 40)

        credential = DefaultAzureCredential()
        ml_client = MLClient.from_config(credential=credential)

        print(f"‚úÖ Conectado: {ml_client.workspace_name}")
        print(f"üìç Regi√£o: {getattr(ml_client, 'location', 'N/A')}")
        print(f"üìä Subscription: {ml_client.subscription_id[:8]}...")

        # 2. Gerenciamento de Compute Clusters
        print("\nGERENCIAMENTO DE COMPUTE CLUSTERS")
        print("-" * 40)

        if os.path.exists('setup_compute_clusters.py'):
            print("‚úÖ Sistema de Compute Clusters dispon√≠vel")

            try:
                from setup_compute_clusters import ComputeManager
                compute_manager = ComputeManager(ml_client)

                print("üìã Listando clusters existentes...")
                existing_clusters = compute_manager.list_all_clusters()

                if not existing_clusters:
                    print("‚ö†Ô∏è  Nenhum compute cluster encontrado")
                    print("üí° Para criar clusters otimizados:")
                    print("   clusters = compute_manager.create_optimized_clusters()")
                else:
                    print(f"‚úÖ {len(existing_clusters)} clusters encontrados")

                # Demonstrar otimiza√ß√µes
                print("\nOtimiza√ß√µes por workload:")
                workloads = ["data_processing", "model_training", "batch_inference"]

                for workload in workloads:
                    print(f"\nüìä {workload.replace('_', ' ').title()}:")
                    recommendation = compute_manager.optimize_cluster_for_workload(workload, 5)

            except Exception as e:
                print(f"‚ö†Ô∏è  Erro ao instanciar ComputeManager: {e}")
        else:
            print("‚ùå setup_compute_clusters.py n√£o encontrado")

        # 3. Data Assets e Lineage
        print("\nDATA ASSETS E LINEAGE")
        print("-" * 40)

        if os.path.exists('data_assets_manager.py'):
            print("‚úÖ Sistema de Data Assets dispon√≠vel")

            try:
                from data_assets_manager import DataAssetsManager
                assets_manager = DataAssetsManager(ml_client)

                print("üìã Listando data assets existentes...")
                existing_assets = assets_manager.list_data_assets()

                if existing_assets:
                    print(f"‚úÖ {len(existing_assets)} assets encontrados")

                    # Demonstrar lineage do primeiro asset
                    first_asset = existing_assets[0]
                    print(f"üîç Analisando lineage: {first_asset.name}")
                    lineage = assets_manager.get_asset_lineage(first_asset.name)
                else:
                    print("‚ö†Ô∏è  Nenhum data asset encontrado")

                # Gerar relat√≥rio de lineage
                print("\nüìä Gerando relat√≥rio de lineage...")
                lineage_report = assets_manager.create_data_lineage_report()

                if os.path.exists("credit_default_dataset.csv"):
                    print("\nüí° Dataset dispon√≠vel para registro como asset:")
                    print("   asset = assets_manager.register_dataset_as_asset('./credit_default_dataset.csv', 'credit_default_raw')")

            except Exception as e:
                print(f"‚ö†Ô∏è  Erro ao instanciar DataAssetsManager: {e}")
        else:
            print("‚ùå data_assets_manager.py n√£o encontrado")

        # 4. Execu√ß√£o de Pipelines na Nuvem
        print("\nEXECU√á√ÉO DE PIPELINES NA NUVEM")
        print("-" * 40)

        if os.path.exists('pipeline_executor.py'):
            print("‚úÖ Sistema de Execu√ß√£o dispon√≠vel")

            try:
                from pipeline_executor import CloudPipelineExecutor
                executor = CloudPipelineExecutor(ml_client)

                print("üìã Listando execu√ß√µes existentes...")
                existing_executions = executor.list_pipeline_executions()

                if existing_executions:
                    print(f"‚úÖ {len(existing_executions)} execu√ß√µes encontradas")
                else:
                    print("‚ö†Ô∏è  Nenhuma execu√ß√£o de pipeline encontrada")

                # Demonstrar capacidades
                print("\nüöÄ Capacidades de execu√ß√£o:")
                print("   ‚Ä¢ submit_data_pipeline() - Submeter pipelines")
                print("   ‚Ä¢ monitor_pipeline_execution() - Monitorar em tempo real")
                print("   ‚Ä¢ get_pipeline_logs() - Obter logs detalhados")

                if os.path.exists("credit_default_dataset.csv"):
                    print("\nüí° Para executar pipeline de dados:")
                    print("   job = executor.submit_data_pipeline('./credit_default_dataset.csv')")
                    print("   status = executor.monitor_pipeline_execution(job.name)")

            except Exception as e:
                print(f"‚ö†Ô∏è  Erro ao instanciar CloudPipelineExecutor: {e}")
        else:
            print("‚ùå pipeline_executor.py n√£o encontrado")

        # 5. Automa√ß√£o de Pipelines
        print("\nAUTOMA√á√ÉO DE PIPELINES")
        print("-" * 40)

        if os.path.exists('pipeline_automation.py'):
            print("‚úÖ Sistema de Automa√ß√£o dispon√≠vel")

            try:
                from pipeline_automation import PipelineAutomation
                automation = PipelineAutomation(ml_client)

                # Demonstrar tipos de triggers
                print("\n‚ö° Tipos de triggers dispon√≠veis:")
                print("   ‚Ä¢ Data Triggers - Baseados em mudan√ßas de dados")
                print("   ‚Ä¢ Schedule Triggers - Execu√ß√£o agendada")
                print("   ‚Ä¢ Conditional Triggers - Condi√ß√µes customizadas")
                print("   ‚Ä¢ Workflow Automation - M√∫ltiplas etapas")

                # Configura√ß√£o exemplo
                pipeline_config_example = {
                    "pipeline_name": "data_processing_pipeline",
                    "compute_cluster": "data-processing-cluster",
                    "experiment_name": "automated_execution"
                }

                print("\nüí° Exemplo de configura√ß√£o de trigger:")
                print("   trigger = automation.create_data_trigger(")
                print("       'new_data_trigger',")
                print("       'credit_default_raw',")
                print("       pipeline_config)")

            except Exception as e:
                print(f"‚ö†Ô∏è  Erro ao instanciar PipelineAutomation: {e}")
        else:
            print("‚ùå pipeline_automation.py n√£o encontrado")

        # 6. Resumo do Sistema Cloud
        print("\nRESUMO DO SISTEMA CLOUD")
        print("-" * 40)

        # Verificar componentes criados
        cloud_components = [
            'setup_compute_clusters.py',
            'data_assets_manager.py',
            'pipeline_executor.py',
            'pipeline_automation.py'
        ]

        components_status = {}
        for component in cloud_components:
            components_status[component] = "‚úÖ" if os.path.exists(component) else "‚ùå"

        print("üìä Status dos componentes:")
        for component, status in components_status.items():
            component_name = component.replace('.py', '').replace('_', ' ').title()
            print(f"   {status} {component_name}")

        # Calcular score de completude
        completed_components = sum(1 for status in components_status.values() if status == "‚úÖ")
        total_components = len(components_status)
        completeness_score = (completed_components / total_components) * 100

        print(f"\nüìà Completude: {completeness_score:.0f}% ({completed_components}/{total_components})")

        # Status geral
        if completeness_score == 100:
            status_emoji = "üéâ"
            status_text = "SISTEMA COMPLETO"
        elif completeness_score >= 75:
            status_emoji = "‚úÖ"
            status_text = "SISTEMA FUNCIONAL"
        else:
            status_emoji = "‚ö†Ô∏è"
            status_text = "SISTEMA INCOMPLETO"

        print(f"{status_emoji} Status: {status_text}")

        # 7. Pr√≥ximos Passos
        print("\nPR√ìXIMOS PASSOS RECOMENDADOS")
        print("-" * 40)

        if completeness_score == 100:
            print("üöÄ Sistema pronto para uso!")
            print("   1. Criar compute clusters otimizados")
            print("   2. Registrar datasets como data assets") 
            print("   3. Executar pipelines na nuvem")
            print("   4. Configurar automa√ß√£o com triggers")
            print("   5. Monitorar execu√ß√µes e custos")
        else:
            print("Completar componentes faltantes:")
            for component, status in components_status.items():
                if status == "‚ùå":
                    print(f"   ‚Ä¢ Execute c√≥digo para criar {component}")

        # 8. Exemplos Pr√°ticos
        print("\nEXEMPLOS PR√ÅTICOS DE USO")
        print("-" * 40)

        print("üí° 1. Criar cluster otimizado:")
        print("   compute_manager = ComputeManager(ml_client)")
        print("   clusters = compute_manager.create_optimized_clusters()")

        print("\nüí° 2. Registrar dataset como asset:")
        print("   assets_manager = DataAssetsManager(ml_client)")
        print("   asset = assets_manager.register_dataset_as_asset('./data.csv', 'my_dataset')")

        print("\nüí° 3. Executar pipeline na nuvem:")
        print("   executor = CloudPipelineExecutor(ml_client)")
        print("   job = executor.submit_data_pipeline('./data.csv')")
        print("   status = executor.monitor_pipeline_execution(job.name)")

        print("\nüí° 4. Configurar automa√ß√£o:")
        print("   automation = PipelineAutomation(ml_client)")
        print("   automation.create_schedule_trigger('daily_job', '@daily', config)")

        return {
            "ml_client": ml_client,
            "components_status": components_status,
            "completeness_score": completeness_score,
            "ready_for_cloud": completeness_score >= 75
        }

    except Exception as e:
        print(f"‚ùå Erro no workflow: {e}")
        return {"error": str(e)}

def test_cloud_connectivity():
    """Testa conectividade com a nuvem"""

    print("\nüîå TESTANDO CONECTIVIDADE COM A NUVEM")
    print("=" * 60)

    connectivity_tests = {
        "Azure Authentication": False,
        "Workspace Connection": False,
        "Compute Access": False,
        "Storage Access": False
    }

    try:
        # Teste 1: Autentica√ß√£o
        print("1Ô∏è‚É£  Testando autentica√ß√£o Azure...")
        credential = DefaultAzureCredential()
        print("‚úÖ Credenciais Azure v√°lidas")
        connectivity_tests["Azure Authentication"] = True

        # Teste 2: Conex√£o com workspace
        print("\n2Ô∏è‚É£  Testando conex√£o com workspace...")
        ml_client = MLClient.from_config(credential=credential)
        print(f"‚úÖ Conectado ao workspace: {ml_client.workspace_name}")
        connectivity_tests["Workspace Connection"] = True

        # Teste 3: Acesso a compute
        print("\n3Ô∏è‚É£  Testando acesso a recursos de compute...")
        try:
            computes = list(ml_client.compute.list())
            print(f"‚úÖ Acesso a compute: {len(computes)} recursos encontrados")
            connectivity_tests["Compute Access"] = True
        except Exception as e:
            print(f"‚ö†Ô∏è  Acesso limitado a compute: {e}")

        # Teste 4: Acesso a storage
        print("\n4Ô∏è‚É£  Testando acesso a storage...")
        try:
            datastores = list(ml_client.datastores.list())
            print(f"‚úÖ Acesso a datastores: {len(datastores)} encontrados")
            connectivity_tests["Storage Access"] = True
        except Exception as e:
            print(f"‚ö†Ô∏è  Acesso limitado a storage: {e}")

        # Resumo dos testes
        print("\nüìä RESUMO DOS TESTES:")
        print("-" * 30)

        passed_tests = sum(connectivity_tests.values())
        total_tests = len(connectivity_tests)

        for test_name, passed in connectivity_tests.items():
            status = "‚úÖ PASS" if passed else "‚ùå FAIL"
            print(f"   {status} {test_name}")

        print(f"\nüèÜ Resultado: {passed_tests}/{total_tests} testes passaram")

        if passed_tests == total_tests:
            print("üéâ Conectividade completa com Azure ML!")
        elif passed_tests >= 2:
            print("‚úÖ Conectividade b√°sica estabelecida")
        else:
            print("‚ö†Ô∏è  Problemas de conectividade detectados")

        return connectivity_tests

    except Exception as e:
        print(f"‚ùå Erro nos testes de conectividade: {e}")
        connectivity_tests["error"] = str(e)
        return connectivity_tests

def show_cloud_architecture_summary():
    """Mostra resumo da arquitetura na nuvem"""

    print("\nARQUITETURA DE EXECU√á√ÉO NA NUVEM")
    print("=" * 60)

    architecture_components = {
        "Compute Layer": {
            "description": "Clusters otimizados para diferentes workloads",
            "components": [
                "Data Processing Cluster (STANDARD_DS3_v2, 0-6 n√≥s)",
                "Model Training Cluster (STANDARD_DS4_v2, 0-4 n√≥s)",
                "Development Cluster (STANDARD_DS2_v2, low priority)",
                "Batch Inference Cluster (STANDARD_DS3_v2, 0-10 n√≥s)"
            ]
        },
        "Data Layer": {
            "description": "Assets versionados com lineage tracking",
            "components": [
                "Data Assets com versionamento autom√°tico",
                "Lineage tracking entre datasets",
                "Metadata rica com tags estruturadas",
                "Storage otimizado no Azure Blob"
            ]
        },
        "Execution Layer": {
            "description": "Orquestra√ß√£o e monitoramento de pipelines",
            "components": [
                "Submiss√£o autom√°tica de pipelines",
                "Monitoramento em tempo real",
                "Logs centralizados e estruturados", 
                "Gest√£o de estados e retry logic"
            ]
        },
        "Automation Layer": {
            "description": "Triggers e workflows automatizados",
            "components": [
                "Data-driven triggers",
                "Schedule-based triggers",
                "Conditional triggers",
                "Multi-stage workflows"
            ]
        }
    }

    for layer_name, layer_info in architecture_components.items():
        print(f"\nüîß {layer_name}")
        print(f"   üìù {layer_info['description']}")
        print("   Componentes:")
        for component in layer_info['components']:
            print(f"     ‚Ä¢ {component}")

    print("\nBENEF√çCIOS DA ARQUITETURA:")
    print("-" * 40)

    benefits = [
        "üîÑ Escalabilidade autom√°tica baseada em demanda",
        "üí∞ Otimiza√ß√£o de custos com auto-scaling e low priority",
        "üìä Observabilidade completa de execu√ß√µes",
        "ü§ñ Automa√ß√£o end-to-end com triggers inteligentes",
        "üîç Rastreabilidade completa com lineage",
        "‚ö° Execu√ß√£o paralela e distribu√≠da",
        "üõ°Ô∏è  Governan√ßa e compliance integrados"
    ]

    for benefit in benefits:
        print(f"   {benefit}")

if __name__ == "__main__":
    # Executar workflow principal
    print("INICIANDO EXECU√á√ÉO NA NUVEM")
    print("=" * 80)

    # Testar conectividade primeiro
    connectivity = test_cloud_connectivity()

    if connectivity.get("Workspace Connection", False):
        # Executar workflow principal se conectividade OK
        result = main_cloud_execution_workflow()

        # Mostrar arquitetura
        show_cloud_architecture_summary()

        print(f"\nStatus: {'‚úÖ SUCESSO' if not result.get('error') else '‚ùå ERRO'}")

        if result.get("ready_for_cloud"):
            print("üéâ Sistema pronto para execu√ß√£o na nuvem!")
        else:
            print("Complete os componentes faltantes")
    else:
        print("\n‚ö†Ô∏è  Conectividade insuficiente para execu√ß√£o completa")
        print("üí° Configure as credenciais Azure e tente novamente")
